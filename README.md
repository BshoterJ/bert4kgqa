# bert4kgqa
An experiment of Chinese KGQA based on BERT_wwm. 
Multi-task learning is used to train BERT for entity linking and relation prediction.
Datasets used here are NLPCC2017KBQA dataset and coresponding KB.

# Requirement
python 3.6
torch 1.0.1
numpy 1.16
tqdm 4.40.0

